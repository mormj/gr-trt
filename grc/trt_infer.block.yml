id: trt_infer
label: infer
category: '[TensorRT]'
templates:
  imports: import trt
  make: trt.infer(${onnx_pathname}, ${type.size}, ${batch_size})

parameters:
- id: type
  label: IO Type
  dtype: enum
  options: [complex, float, int, short, byte]
  option_attributes:
    size: [gr.sizeof_float, gr.sizeof_float, gr.sizeof_int, gr.sizeof_short,
        gr.sizeof_char]
  hide: part
  default: float
- id: onnx_pathname
  label: ONNX Model
  dtype: string
- id: batch_size
  label: Batch_size
  default: 1
  dtype: int
inputs:
- label: in
  domain: stream
  dtype: ${type}
outputs:
- label: out
  domain: stream
  dtype: ${type}

file_format: 1
